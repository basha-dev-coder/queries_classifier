{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset banking77 (C:\\Users\\barka\\.cache\\huggingface\\datasets\\banking77\\default\\1.1.0\\aec0289529599d4572d76ab00c8944cb84f88410ad0c9e7da26189d31f62a55b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6a3c66237842b789997bac19b21b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset  = load_dataset('banking77')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(dataset['train'])\n",
    "test_df = pd.DataFrame( dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_valid,y_train,y_valid = train_test_split(train_df['text'],train_df['label'],stratify=train_df['label'],test_size=0.1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train,y_train)).batch(32).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_valid,y_valid)).batch(32).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_df['text'],test_df['label'])).batch(32).cache().prefetch(buffer_size=AUTOTUNE,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=string, numpy=b'I want to auto top-up.'>,\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=4>)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_batch_1, text_label_1 = next(iter(train_ds)) # pick first batch from dataset\n",
    "text , label = text_batch_1[0],text_label_1[0] # taking first text and label from batch\n",
    "text , label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_text as text  # Registers the ops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "text_input = tf.keras.Input(shape=(),dtype=tf.string,name=\"input_layer\")\n",
    "preprocessor = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',name=\"preprocessor\")\n",
    "encoder_inputs = preprocessor(text_input)\n",
    "\n",
    "encoder = hub.KerasLayer('https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/2',trainable=True,name='BERT_encoder')\n",
    "outputs = encoder(encoder_inputs)\n",
    "\n",
    "pooled_output = outputs['pooled_output']\n",
    "\n",
    "#create Dense layer for classifier\n",
    "# net = tf.keras.layers.Dropout(0.1)(pooled_output)\n",
    "net = tf.keras.layers.Dense(77,activation='softmax')(pooled_output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have been waiting over a week. Is the card still coming?'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[2,'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.01573822 0.00680786 0.00682698 0.0057435  0.00663491 0.00416449\n",
      "  0.00671658 0.00300336 0.00776005 0.02080373 0.00809656 0.01633636\n",
      "  0.01218717 0.02530308 0.00674909 0.10578006 0.01120544 0.0274372\n",
      "  0.02170157 0.01573708 0.01062904 0.00761745 0.00695283 0.00173848\n",
      "  0.01317095 0.00980883 0.01405094 0.00347213 0.01154466 0.00719797\n",
      "  0.00762379 0.01444083 0.00922981 0.02476273 0.002159   0.00631858\n",
      "  0.00529782 0.01209983 0.01630371 0.03186492 0.02393494 0.04164134\n",
      "  0.0033001  0.02736972 0.00330217 0.01364071 0.0066231  0.00550543\n",
      "  0.00821105 0.00769989 0.01056043 0.00515484 0.01237898 0.01605432\n",
      "  0.02369267 0.00198569 0.01726761 0.01083891 0.01656568 0.01373474\n",
      "  0.01385983 0.00742864 0.00661014 0.01571984 0.01459891 0.01259194\n",
      "  0.00986702 0.01351462 0.00586727 0.00526361 0.00591046 0.01368266\n",
      "  0.005771   0.01596901 0.00332802 0.0143096  0.01522762]], shape=(1, 77), dtype=float32) tf.Tensor([15], shape=(1,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "embedding_model = tf.keras.Model(text_input, net)\n",
    "sentences = tf.constant([\"I have been waiting over a week. Is the card still coming?\"])\n",
    "print(embedding_model(sentences) , tf.math.argmax(embedding_model(sentences),1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_layer (InputLayer)       [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " preprocessor (KerasLayer)      {'input_type_ids':   0           ['input_layer[0][0]']            \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_mask': (Non                                               \n",
      "                                e, 128)}                                                          \n",
      "                                                                                                  \n",
      " BERT_encoder (KerasLayer)      {'default': (None,   4385921     ['preprocessor[0][0]',           \n",
      "                                128),                             'preprocessor[0][1]',           \n",
      "                                 'pooled_output': (               'preprocessor[0][2]']           \n",
      "                                None, 128),                                                       \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 128, 128),                                                \n",
      "                                 'encoder_outputs':                                               \n",
      "                                 [(None, 128, 128),                                               \n",
      "                                 (None, 128, 128)]}                                               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 128)          0           ['BERT_encoder[0][3]']           \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 77)           9933        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,395,854\n",
      "Trainable params: 4,395,853\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_SIZE = train_df.shape[0]\n",
    "BATCH_SIZE = 32\n",
    "VAL_BATCH  = int((TOTAL_SIZE / BATCH_SIZE) * 0.9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int((TOTAL_SIZE / BATCH_SIZE) * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.take(VAL_BATCH)\n",
    "val_ds = train_ds.skip(VAL_BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "# steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "# num_train_steps = steps_per_epoch * epochs\n",
    "# num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "# init_lr = 3e-5\n",
    "# optimizer = tf.keras.optimization.create_optimizer(init_lr=init_lr,\n",
    "#                                           num_train_steps=num_train_steps,\n",
    "#                                           num_warmup_steps=num_warmup_steps,\n",
    "#                                           optimizer_type='adamw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "                         loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                         metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "282/282 [==============================] - 73s 252ms/step - loss: 4.5300 - accuracy: 0.0163 - val_loss: 4.3697 - val_accuracy: 0.0310\n",
      "Epoch 2/5\n",
      "282/282 [==============================] - 73s 257ms/step - loss: 4.3042 - accuracy: 0.0401 - val_loss: 4.1415 - val_accuracy: 0.0579\n",
      "Epoch 3/5\n",
      "282/282 [==============================] - 73s 260ms/step - loss: 4.1321 - accuracy: 0.0625 - val_loss: 3.9518 - val_accuracy: 0.1049\n",
      "Epoch 4/5\n",
      "282/282 [==============================] - 70s 250ms/step - loss: 3.9526 - accuracy: 0.1019 - val_loss: 3.7399 - val_accuracy: 0.1628\n",
      "Epoch 5/5\n",
      "282/282 [==============================] - 70s 248ms/step - loss: 3.7677 - accuracy: 0.1501 - val_loss: 3.5169 - val_accuracy: 0.2288\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2005267c310>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.fit(train_ds,validation_data=val_ds,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 6s 67ms/step - loss: 3.5506 - accuracy: 0.2000\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = embedding_model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 6s 60ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = embedding_model.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = test_ds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in train_ds.take(1):\n",
    "    print(x,y)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 77ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.06842163, 0.00334039, 0.00698865, ..., 0.00877284, 0.00494816,\n",
       "        0.00503086],\n",
       "       [0.03302078, 0.00379312, 0.0133736 , ..., 0.00748981, 0.02237591,\n",
       "        0.01538504],\n",
       "       [0.05113184, 0.00421031, 0.00963745, ..., 0.00564119, 0.02267505,\n",
       "        0.00645326],\n",
       "       ...,\n",
       "       [0.04194529, 0.00361456, 0.00887997, ..., 0.01052712, 0.0054382 ,\n",
       "        0.00625578],\n",
       "       [0.02375717, 0.00542869, 0.01179141, ..., 0.00801594, 0.02415427,\n",
       "        0.01230364],\n",
       "       [0.01862687, 0.00712863, 0.01008906, ..., 0.00598353, 0.02096801,\n",
       "        0.0128925 ]], dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.predict(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = tf.math.argmax(preds,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
       "array([ 0, 53, 53, 36, 53,  0, 47,  0, 15, 47, 21, 52, 45, 45, 47, 45, 30,\n",
       "       53, 47, 30, 30,  0, 53, 30, 63, 15, 30, 30, 30, 58, 53, 30],\n",
       "      dtype=int64)>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'How do I locate my card?'\n",
      " b'I still have not received my new card, I ordered over a week ago.'\n",
      " b'I ordered a card but it has not arrived. Help please!'\n",
      " b'Is there a way to know when my card will arrive?'\n",
      " b'My card has not arrived yet.' b'When will I get my card?'\n",
      " b'Do you know if there is a tracking number for the new card you sent me?'\n",
      " b'i have not received my card' b'still waiting on that card'\n",
      " b'Is it normal to have to wait over a week for my new card?'\n",
      " b'How do I track my card?' b'How long does a card delivery take?'\n",
      " b\"I still don't have my card after 2 weeks.  What should I do?\"\n",
      " b'still waiting on my new card'\n",
      " b'I am still waiting for my card after 1 week.  Is this ok?'\n",
      " b'I have been waiting longer than expected for my bank card, could you provide information on when it will arrive?'\n",
      " b\"I've been waiting longer than expected for my card.\"\n",
      " b\"Why hasn't my card been delivered?\"\n",
      " b'Where is my new card? I have been waiting a week!'\n",
      " b\"My card still hasn't arrived after 2 weeks. Is it lost?\"\n",
      " b'I did not get my card yet, is it lost?'\n",
      " b'Status of the card I ordered.'\n",
      " b'How long should my new card take to arrive?'\n",
      " b\"I ordered my card 2 weeks ago and it still isn't here? What do I do?\"\n",
      " b'My card has not arrived yet, where is it?'\n",
      " b'What is the tracking number for my card that was mailed?'\n",
      " b\"I think something went wrong with my card delivery as I haven't received it yet.\"\n",
      " b\"I'm still waiting for delivery of my new card, why is it taking so long?\"\n",
      " b\"I ordered a card a week ago, and it's still not here. What do I do?\"\n",
      " b'i want to track the card you sent' b\"My card hasn't arrived yet.\"\n",
      " b\"I was expecting my new card and am wondering why I haven't received it yet?\"], shape=(32,), dtype=string) tf.Tensor(\n",
      "[11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11], shape=(32,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for x,_ in test_ds.take(1):\n",
    "    print(x,_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_model = hub.load(\n",
    "    \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "special_tokens_dict = preprocessor_model.tokenize.get_special_tokens_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_inputs = [tf.keras.layers.Input(shape=(), dtype=tf.string)]\n",
    "tokenize = hub.KerasLayer(preprocessor_model.tokenize)\n",
    "tokenized_inputs = [tokenize(segment) for segment in text_inputs]\n",
    "\n",
    "# Step 2 (optional): modify tokenized inputs.\n",
    "pass\n",
    "\n",
    "# Step 3: pack input sequences for the Transformer encoder.\n",
    "seq_length = 128  # Your choice here.\n",
    "bert_pack_inputs = hub.KerasLayer(\n",
    "    preprocessor_model.bert_pack_inputs,\n",
    "    arguments=dict(seq_length=seq_length))  # Optional argument.\n",
    "encoder_inputs = bert_pack_inputs(tokenized_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs(tf.constant([\"I was expecting my new card and am wondering why I haven't received it yet?\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_word_ids': <KerasTensor: shape=(None, 128) dtype=int32 (created by layer 'keras_layer_7')>,\n",
       " 'input_type_ids': <KerasTensor: shape=(None, 128) dtype=int32 (created by layer 'keras_layer_7')>,\n",
       " 'input_mask': <KerasTensor: shape=(None, 128) dtype=int32 (created by layer 'keras_layer_7')>}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ccc9907020a360c0774b7240d7189d7caac06a5804f44f1a6c385a36278d3a41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
