{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing necessary libraries\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow_text as text\n",
    "import wandb\n",
    "import tensorflow_hub as hub\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing W&B run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"banking_77\"\n",
    "JOB_TYPE = \"baseline\"\n",
    "ENTITY = \"basha\"\n",
    "SPLIT_DATA = \"preprocess\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: basha. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Automation\\python\\Yelp_review\\wandb\\run-20220723_125429-28x50v4g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/basha/banking_77/runs/28x50v4g\" target=\"_blank\">leafy-snowball-4</a></strong> to <a href=\"https://wandb.ai/basha/banking_77\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=PROJECT_NAME,job_type=JOB_TYPE,entity=ENTITY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching data of W&B Artifact\n",
    "We are downloading preprocesed data from W&B and batching the dataset using tf.data. This will help to use GPU when try to use the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = run.use_artifact(f'{SPLIT_DATA}:latest')\n",
    "split_dir = split.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{split_dir}//train_split.csv')\n",
    "valid_df = pd.read_csv(f'{split_dir}//valid_split.csv')\n",
    "test_df = pd.read_csv(f'{split_dir}//test_split.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_df['text'],train_df['label'])).batch(32).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "valid_ds = tf.data.Dataset.from_tensor_slices((valid_df['text'],valid_df['label'])).batch(32).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_df['text'],test_df['label'])).batch(32).cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=string, numpy=b'Will you send me a new card in China?'>,\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=9>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_batch_1, text_label_1 = next(iter(train_ds)) # pick first batch from dataset\n",
    "text , label = text_batch_1[0],text_label_1[0] # taking first text and label from batch\n",
    "text , label # prints first text and label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging model configuration in W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_collections import config_dict\n",
    "\n",
    "cfg = config_dict.ConfigDict()\n",
    "cfg.preprocessor = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
    "cfg.encoder = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/2'\n",
    "cfg.bs = 32\n",
    "cfg.seed = 42\n",
    "cfg.arch = 'bert_L-2_H-128_A-2'\n",
    "cfg.learning_rate = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config.update(cfg.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    text_input = tf.keras.Input(shape=(),dtype=tf.string,name=\"input_layer\")\n",
    "    preprocessor = hub.KerasLayer(cfg.preprocessor,name=\"preprocessor\")\n",
    "    encoder_inputs = preprocessor(text_input)\n",
    "\n",
    "    encoder = hub.KerasLayer(cfg.encoder,trainable=True,name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "\n",
    "    pooled_output = outputs['pooled_output']\n",
    "\n",
    "    #create Dense layer for classifier\n",
    "    # net = tf.keras.layers.Dropout(0.1)(pooled_output)\n",
    "    net = tf.keras.layers.Dense(77,activation='softmax')(pooled_output) #predict 77 classes\n",
    "    return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Creating and compiling a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=cfg.learning_rate),\n",
    "                         loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                         metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\barka\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\profiler\\internal\\flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\barka\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\profiler\\internal\\flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "282/282 [==============================] - 77s 260ms/step - loss: 4.5127 - accuracy: 0.0149 - val_loss: 4.3682 - val_accuracy: 0.0220 - _timestamp: 1658580047.0000 - _runtime: 2778.0000\n",
      "Epoch 2/5\n",
      "282/282 [==============================] - 69s 246ms/step - loss: 4.3332 - accuracy: 0.0312 - val_loss: 4.1932 - val_accuracy: 0.0599 - _timestamp: 1658580116.0000 - _runtime: 2847.0000\n",
      "Epoch 3/5\n",
      "282/282 [==============================] - 73s 258ms/step - loss: 4.1778 - accuracy: 0.0514 - val_loss: 3.9731 - val_accuracy: 0.1129 - _timestamp: 1658580189.0000 - _runtime: 2920.0000\n",
      "Epoch 4/5\n",
      "282/282 [==============================] - 72s 256ms/step - loss: 3.9721 - accuracy: 0.1088 - val_loss: 3.7191 - val_accuracy: 0.1998 - _timestamp: 1658580261.0000 - _runtime: 2992.0000\n",
      "Epoch 5/5\n",
      "282/282 [==============================] - 77s 274ms/step - loss: 3.7723 - accuracy: 0.1656 - val_loss: 3.4729 - val_accuracy: 0.2687 - _timestamp: 1658580338.0000 - _runtime: 3069.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x131b8390280>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds,validation_data=valid_ds,epochs=5,callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 7s 65ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = tf.math.argmax(preds,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int64, numpy=array([39], dtype=int64)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.argmax(model.predict(tf.constant(['How do I locate my card?'])),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['predicted'] = preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging Predictions table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log({'predictions_table': wandb.Table(dataframe=test_df)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 20s 72ms/step - loss: 3.4553 - accuracy: 0.2728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.4553279876708984, 0.27282825112342834]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_ds) # train set predicitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 2s 71ms/step - loss: 3.4729 - accuracy: 0.2687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.4728615283966064, 0.2687312662601471]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(valid_ds) # valid set predicitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shutting down W&B run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20a5d5abfdb4759a2f531f18d2ae961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='51.505 MB of 51.505 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▂▃▅█</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>loss</td><td>█▆▅▃▁</td></tr><tr><td>val_accuracy</td><td>▁▂▄▆█</td></tr><tr><td>val_loss</td><td>█▇▅▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPS</td><td>0.00094</td></tr><tr><td>accuracy</td><td>0.16563</td></tr><tr><td>best_epoch</td><td>4</td></tr><tr><td>best_val_loss</td><td>3.47286</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>loss</td><td>3.77234</td></tr><tr><td>val_accuracy</td><td>0.26873</td></tr><tr><td>val_loss</td><td>3.47286</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">leafy-snowball-4</strong>: <a href=\"https://wandb.ai/basha/banking_77/runs/28x50v4g\" target=\"_blank\">https://wandb.ai/basha/banking_77/runs/28x50v4g</a><br/>Synced 5 W&B file(s), 2 media file(s), 4 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220723_125429-28x50v4g\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ccc9907020a360c0774b7240d7189d7caac06a5804f44f1a6c385a36278d3a41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
